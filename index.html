<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Start SEO -->
  <meta name="description"
    content="Person website for Andre Telfer, a graduate student working on Neuroscience and Deep Learning problems.">
  <meta name="keywords"
    content="Andre Telfer, Telfer, Andre, Ottawa, Canada, Research, Deep Learning, Artificial Intelligence, AI, Machine Learning, ML, Computer Vision, Automated, Neuroscience, Computer Science, Behaviour, Mice, Mouse">
  <meta name="author" content="Andre Telfer">

  <!-- content schema for crawlers https://schema.org/Person -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "email": "mailto:andretelfer@cmail.carleton.ca",
      "sameAs": "https://www.linkedin.com/in/andretelfer",
      "jobTitle": "Student, MSc Neuroscience",
      "name": "Andre Telfer",
      "givenName": "Andre",
      "familyName": "Telfer",
      "url": "https://a-telfer.github.io/"
    }
  </script>

  <!-- Google search console for checking SEO https://search.google.com/search-console/welcome?utm_source=about-page -->
  <meta name="google-site-verification" content="YwxOb5svPyAYpbEgIKCrY4Ey2tz-4ov2WoR7JExH9Ws" />
  <!-- End SEO  -->

  <!-- FavIcons https://favicon.io/favicon-generator/ -->
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <!-- Local CSS -->
  <link rel="stylesheet" href="assets/css/starter.css">
  <title>A.Telfer</title>
</head>

<body>
  <!-- Navbar -->
  <nav class="navbar navbar-expand-md">
    <div class="container-fluid">
      <a class="navbar-brand" href="/">Andre Telfer </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="navbar-collapse" id="navbarNav">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" href="#profile">{ Research Interest }</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#background">{ Background }</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#msc-thesis">{ Thesis }</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#posters">{ Posters }</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" aria-current="page" href="#projects">{ Projects }</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="col-md-8 py-5 px-3 mx-auto">
    <header class="pb-3 mb-5 mt-3" id="header">
      <h1 class="h3 justify-content-center">
        <a href="#header" class="d-flex align-items-center text-decoration-none">
          <!-- <svg width="48" height="48" viewBox="0 0 12.7 12.7" version="1.1" id="svg12390"
            inkscape:version="1.1.2 (0a00cf5339, 2022-02-04)" sodipodi:docname="logo.svg"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
            xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg"
            xmlns:svg="http://www.w3.org/2000/svg">
            <g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1">
              <g id="g11984" inkscape:transform-center-x="2.5126138" inkscape:transform-center-y="1.7842468"
                transform="matrix(-0.62162725,-0.73245239,-0.73245239,0.62162725,107.93749,22.096524)" />
              <path id="circle5072"
                style="font-variation-settings:normal;vector-effect:none;fill:currentColor;fill-opacity:1;fill-rule:evenodd;stroke-width:0.960684;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1;-inkscape-stroke:none;stop-color:#000000"
                d="M 23.707031 1.3476562 A 22.54137 22.54137 0 0 0 1.1660156 23.888672 A 22.54137 22.54137 0 0 0 23.707031 46.431641 A 22.54137 22.54137 0 0 0 46.25 23.888672 A 22.54137 22.54137 0 0 0 23.707031 1.3476562 z M 21.458984 8.4980469 L 25.755859 8.4980469 L 36.431641 36.511719 L 32.492188 36.511719 L 29.939453 29.326172 L 17.3125 29.326172 L 14.759766 36.511719 L 10.763672 36.511719 L 21.458984 8.4980469 z M 23.597656 12.232422 L 18.457031 26.173828 L 28.757812 26.173828 L 23.597656 12.232422 z "
                transform="scale(0.26458333)" />
              <g aria-label="A" id="text10237"
                style="font-size:10.1672px;line-height:1.25;word-spacing:0px;fill:#ffffff;stroke-width:0.254181" />
            </g>
          </svg>&nbsp; -->
          
          <span style="font-size:3rem;">Andre Telfer</span>
        </a>
      </h1>
      <p class="lead">Graduate Student, Department of Neuroscience, Carleton University.</p>
      Contact: <a href="mailto:andretelfer@cmail.carleton.ca?subject=Hi!">andretelfer@cmail.carleton.ca</a>
    </header>

    <h2 id="profile">RESEARCH INTERESTS</h2>
    <div class="row">
      <div class="col-sm-4 mb-4">
        <div class="card" style="width: 100%;">
          <img class="card-img-top" style="filter: brightness(80%);" src="assets/images/dalle-camera.png"  alt="Card image cap">
          <h4 class="card-title text-center mt-1">Computer Vision</h4>
        </div>
      </div>

      <div class="col-sm-4 mb-4">
        <div class="card" style="width: 100%;">
          <img class="card-img-top" src="assets/images/dalle-computer.png"  alt="Card image cap">
          <h4 class="card-title text-center mt-1">Machine Learning</h4>
        </div>
      </div>

      <div class="col-sm-4 mb-4">
        <div class="card" style="width: 100%;">
          <img class="card-img-top" src="assets/images/dalle-brain.png"  alt="Card image cap">
          <h4 class="card-title text-center mt-1">Neuroscience</h4>
        </div>
      </div>
    </div>

    <div class="row mt-3 mb-3">
      <div class="col-lg-4 col-sm-12 mb-3">
        <h3 id="background">BACKGROUND</h3>
        <ul>
          <li>Student, MSc Neuroscience.</li>
          <li>BCs Computer Science, Math Minor.</li>
          <li>Carleton University, Ottawa, Canada.</li>
        </ul>
      </div>

      <div class="col-lg-8 col-sm-12 mb-3">
        <h3 id="msc-thesis">MSc THESIS</h3>
        <p>
          My research revolves around bringing Computer Science tools to analyze Neuroscience problems.
          For my thesis, I'm developing tools for automated scoring of animal behaviour using computer vision.
          In particular, my work focuses on stress and emotionality recognition.

          I'm passionate about collaborating with groups on different Neuroscience datasets and invite anyone interested to <a
            href="mailto:andretelfer@cmail.carleton.ca">send me an email</a>.
        </p>
      </div>
    </div>

    <div class="row mb-5">
      <h3 id="posters">POSTERS</h3>
      <hr class="my-2" />
      <div class="accordion accordion-flush" id="accordionFlushExample">
        <div class="accordion-item">
          <h2 class="accordion-header" id="flush-headingOne">
            <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
              data-bs-target="#flush-collapseOne" aria-expanded="false" aria-controls="flush-collapseOne">
              CAN-ACN Poster 2022
            </button>
          </h2>
          <div id="flush-collapseOne" class="accordion-collapse collapse" aria-labelledby="flush-headingOne"
            data-bs-parent="#accordionFlushExample">
            <div class="accordion-body">
              <a class="no-highlight" href="assets/images/telfer-can2022.png" target="blank_">
                <img class="img-fluid" style="filter: brightness(90%);" src="assets/images/telfer-can2022-thumbnail.jpg" />
              </a>
            </div>
          </div>
        </div>
        <div class="accordion-item">
          <h2 class="accordion-header" id="flush-headingTwo">
            <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
              data-bs-target="#flush-collapseTwo" aria-expanded="false" aria-controls="flush-collapseTwo">
              SFN Poster 2021
            </button>
          </h2>
          <div id="flush-collapseTwo" class="accordion-collapse collapse show" aria-labelledby="flush-headingTwo"
            data-bs-parent="#accordionFlushExample">
            <div class="accordion-body">
              <div class="accordion-body">
                <a class="no-highlight" href="assets/images/telfer-sfn2021.png" target="blank_">
                  <img class="img-fluid" style="filter: brightness(90%);" src="assets/images/telfer-sfn2021-thumbnail.jpg" />
                </a>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Projects -->
    <h3 id="projects">ONGOING PROJECTS</h3>
    <div id="projects-content" class="row">

      <div class="col-sm-6 col-lg-4 mb-4">
        <a class="no-highlight" data-bs-toggle="modal" data-bs-target="#oft-modal">
          <div class="highlight-on-hover">

            <div class="card">
              <img class="card-img-top" src="assets/images/oft-dashboard-thumbnail.jpg" alt="">
              <div class="card-body">
                <h5 class="card-title">What comes after DeepLabCut: Open Field Test Analysis</h5>
                <p class="card-text">Simple code for turning DeepLabCut outputs into meaningful results and publishable
                  figures.</p>
              </div>
            </div>
          </div>
        </a>

        <div class="modal fade" id="oft-modal" tabindex="-1" aria-labelledby="oftModalLabel" aria-hidden="true">
          <div class="modal-dialog modal-dialog-centered modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h5 class="modal-title" id="oftModalLabel">Deep-learning scoring of the Open Field Test
                  Expressions</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
              </div>
              <div class="modal-body">
                <h6>Description</h6>
                <p>
                  In Neuroscience, behavioural studies in animals are a key component to understanding how the brain
                  functions to generate complex cognitive, motivational, and emotional processes. Behavioural assays are
                  a cornerstone of this behavioural research, and the Open Field Test (OFT) is a common behavioural
                  assay used to test the anxiolytic effects of drugs, motivation, locomotor activity, fear responses and
                  exploration
                </p>
                <p>
                  Experiments using the OFT generate many hours of video which need to be carefully scored.
                  Manual analysis of these videos is a labour intensive process, in many cases taking weeks, and is
                  prone to reliability/consistency issues.
                  Several commercial automated tools exist for scoring OFT videos. However these tools are very
                  expensive,
                  and may perform worse than more recent Open Source solutions [<a
                    href="https://www.nature.com/articles/s41386-020-0776-y" target="blank_">ref</a>] (for example, they
                  may struggle with wires moving in front of the camera).
                  Furthermore, the Open Field Test is frequently modified and closed-source nature of commercial
                  solution drives many researchers back to manual scoring if their needs are not met in entirety.
                </p>

                <p>
                  This project uses an open source deep learning tool (<a
                    href="https://github.com/DeepLabCut/DeepLabCut">DeepLabCut</a>) in order to automate scoring of OFT
                  videos.
                  We introduce a video calibration step in order to account for differences between videos (current
                  tools favour a fixed setup which many labs using shared experimental spaces do not have) and more
                  accurately translate between pixels and real distance units.
                  We also introduce an API that allows researchers to extract new features from dozens of hours of video
                  in only a few lines of code.
                </p>

                <h6>Collaborators</h6>
                <p>Dr. John Lewis (University of Ottawa), Dr. Oliver van Kaick (Carleton University), Dr. Alfonso
                  Abizaid (Carleton University)</p>

                <h6>Links</h6>
                <a
                  href="https://github.com/A-Telfer/bapipe-keypoints/tree/fd24e3c7b16bd9901db95f3bbc46efc6f13268f6">https://github.com/A-Telfer/bapipe-keypoints</a>
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-bs-dismiss="modal">Close</button>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <a class="no-highlight" data-bs-toggle="modal" data-bs-target="#facial-expressions-modal">
          <div class="highlight-on-hover">

            <div class="card">
              <img class="card-img-top" src="assets/images/mouse-facial-expressions-thumbnail.jpg" alt="">
              <div class="card-body">
                <h5 class="card-title">Facial Expressions of Mice</h5>
                <p class="card-text">Recognizing mouse wellness from facial expressions.</p>
              </div>
            </div>
          </div>
        </a>

        <div class="modal fade" id="facial-expressions-modal" tabindex="-1"
          aria-labelledby="facialExpressionsModalLabel" aria-hidden="true">
          <div class="modal-dialog modal-dialog-centered modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h5 class="modal-title" id="facialExpressionsModalLabel">Automated Classificatio of Mouse Facial
                  Expressions</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
              </div>
              <div class="modal-body">
                <h6>Description</h6>
                <p>
                  Many species exhibit facial expressions corressponding to different states of emotion and wellbeing.
                  Mice are one such species that exhibit facial expressions and recent work has highlighted the ability
                  for DeepLearning (/AI) to automatically recognize
                  them in free-moving mice<a
                    href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0228059"
                    target="_blank">[1]</a>.
                  Models like these could be widely applied to behavioural research in order to improve animal care.
                  Additionally, it potentially offers a new dimension of emotionality data compared to older methods
                  such as the Open Field Test.
                </p>
                <p>
                  Automatic classification of mouse wellbeing based on facial expressions.
                </p>
                <h6>Collaborators</h6>
                <p>Niek Andresen, Dr. Katharina Hohlbaum, Dr. Alfonso Abizaid</p>
                <h6>Links</h6>
                <a href="https://github.com/A-Telfer/mouse-facial-expressions/tree/main/hohlbaum_black_mouse_dataset"
                  target="_blank">BMv1 Well Being Benchmark</a>
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-bs-dismiss="modal">Close</button>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <a class="no-highlight" data-bs-toggle="modal" data-bs-target="#microscopy-modal">
          <div class="highlight-on-hover">

            <div class="card">
              <img class="card-img-top"
                src="https://a-telfer.github.io/cfos-automatic-cell-counting/_images/screenshot-napari-zone.png" alt="">
              <div class="card-body">
                <h5 class="card-title">Cell Counting using Deep Learning</h5>
                <p class="card-text">Quantifying intense activation of neurons through automatic counting of c-Fos
                  expressing cells.</p>
              </div>
            </div>
          </div>
        </a>
        <div class="modal fade" id="microscopy-modal" tabindex="-1" aria-labelledby="microscopyModalLabel"
          aria-hidden="true">
          <div class="modal-dialog modal-dialog-centered modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h5 class="modal-title" id="microscopyModalLabel">Cell Counting using Deep Learning</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
              </div>
              <div class="modal-body">
                <h6>Description</h6>
                <p>
                  c-Fos expression can occur in neurons after intense activation, and can provide information on cell
                  growth and plasticity <a href="https://www.frontiersin.org/article/10.3389/fncel.2015.00072"
                    target="_blank">[ref]</a>. Currently, manual cell counting is the gold standard. This is time
                  intensive
                  and often takes many weeks,
                  as experiments can produce hundreds of images, each with hundreds of c-Fos expressing cells.
                </p>
                <p>ImageJ is a tool that has been used to semi-automate cell counting. The downside of this approach is
                  that
                  parameters such as pixel intensity thresholds, cell sizes, and cell shapes may need to be adjusted per
                  image. Additionally, images that contain areas of background noise are difficult to extract accurate
                  cell
                  counts from.</p>
                <p>Here we explore alternative methods for performing cell counting for c-Fos expressing cells.</p>
                <h6>Collaborators</h6>
                <p>Aylar Rahimi, Brenna MacAuley, Andrea Smith, Dr. Alfonso Abizaid</p>
                <h6>Links</h6>
                <a
                  href="https://a-telfer.github.io/cfos-automatic-cell-counting/yolov5/creating-dataset-by-sampling-cell-images.html">
                  YOLO c-Fos Expression Detection
                </a>
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-bs-dismiss="modal">Close</button>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <a class="no-highlight" data-bs-toggle="modal" data-bs-target="#gait-modal">
          <div class="highlight-on-hover">

            <div class="card">

              <img class="card-img-top" src="assets/images/gait-analysis-thumbnail.jpg" alt="">
              <div class="card-body">
                <h5 class="card-title">Gait Analysis: Mice Walk Silly Too</h5>
                <p class="card-text">Tracking dysfunction/degeneration in neural circuits through passive gait analysis.
                </p>
              </div>
            </div>
          </div>
        </a>

        <div class="modal fade" id="gait-modal" tabindex="-1" aria-labelledby="gaitModalLabel" aria-hidden="true">
          <div class="modal-dialog modal-dialog-centered modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h5 class="modal-title" id="gaitModalLabel">Gait Analysis in Mice</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
              </div>
              <div class="modal-body">
                <h6>Description</h6>
                <p>
                  In both humans and mice, gait analysis has been used to observe dysfunction in the brain.
                  Gait analysis has been used to provide a measure of brain dysfunction in Parkinson's Disease,
                  Huntington's Disease, Stroke, and Multiple Sclerosis.
                  Mouse models of these conditions also observe changes gait.

                  Traditional systems for performing gait analysis in mice often require the mice to be placed in a
                  specific environment. For treadmill based systems
                  This project aims at performing automatic gait analysis using deep learning with fewer setup
                  constraints.
                </p>
                <h6>Collaborators</h6>
                <p>Vanessa Wong, Emmerson Borthwick, Dana Wymark, Delenn Hills</p>
                <!-- <h6>Links</h6>
                <p>...</p> -->
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-bs-dismiss="modal">Close</button>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <a class="no-highlight" data-bs-toggle="modal" data-bs-target="#maternal-behavior-modal">
          <div class="highlight-on-hover">

            <div class="card">
              <img class="card-img-top" src="assets/images/maternal-example-thumbnail.jpg" alt="">
              <div class="card-body">
                <h5 class="card-title">Behavioural Classification on 151 Days of Video</h5>
                <p class="card-text">
                  Automatic scoring of maternal behaviours in low quality videos spanning over 3633 hours.
                </p>
              </div>
            </div>
          </div>
        </a>

        <div class="modal fade" id="maternal-behavior-modal" tabindex="-1" aria-labelledby="exampleModalLabel"
          aria-hidden="true">
          <div class="modal-dialog modal-dialog-centered modal-lg">
            <div class="modal-content">
              <div class="modal-header">
                <h5 class="modal-title" id="exampleModalLabel">Maternal Dataset: Behavior Classification of 151 Days of
                  Video</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
              </div>
              <div class="modal-body">
                <h6>Description</h6>
                <p>Automated scoring of maternal behaviours such as grooming pups, fetching, and feeding, throughout the
                  day/night cycle. Dataset contains over 3600 hours of video.</p>
                <h6>Collaborators</h6>
                <p>Ben Nikkel, Dr. Alfonso Abizaid</p>
                <!-- <h6>Links</h6>
          <p>...</p> -->
              </div>
              <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-bs-dismiss="modal">Close</button>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Classification of events in Neuronal Dynamics</h5>
            <p class="card-text">Time series applications of Deep Learning</p>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Neural Plasticity in Children with Congenital Total-blindness</h5>
            <p class="card-text">Using deep learning to track focus in an indented image recognition task.</p>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Inverse Kinematics of Mouse Motion</h5>
            <p class="card-text">Inferring full 3D geometry and motion of mouse gait from 2D pose data.</p>
          </div>
        </div>
      </div>
    </div>

    <!-- <hr class="my-2" />
    <h2 id="projects">PROJECTS</h2>
    <div id="projects-content" class="row">
      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Biocoders co-founder</h5>
            <p class="card-text">Supporting researchers developing coding skills at Carleton University and the
              University of Ottawa</p>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Preprocessing Behavioural Data</h5>
            <p class="card-text">Preparing datasets for analysis pipelines.</p>
            <a
              href="https://a-telfer.github.io/preprocessing-behavior-videos/transcoding-large-experiments.html">Transcoding</a>
            <a href="https://a-telfer.github.io/preprocessing-behavior-videos/datasheet-cleanup.html">Datasheet
              Cleanup</a>
          </div>
        </div>
      </div>

      <div class="col-sm-6 col-lg-4 mb-4">
        <div class="card">
          <div class="card-body">
            <h5 class="card-title">Practical math and the code to do it, for Neuroscientists</h5>
            <p class="card-text">PCA, t-SNE, UMAP, Fourier, and other concepts applied to neuroscience data.</p>
          </div>
        </div>
      </div>
    </div> -->

    <!-- <hr class="my-2 mb-5" /> -->


    

    <!-- Profile, Background, Contact -->


    <hr class="my-5">
    <p class="text-muted">andretelfer@cmail.carleton.ca.</p>
  </div>

  <!-- Masonry https://getbootstrap.com/docs/5.0/examples/masonry -->
  <script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
    integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D"
    crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>

  <script src="https://code.jquery.com/jquery-3.6.0.min.js"
    integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="node_modules/jquery/dist/jquery.slim.min.js"></script>
  <script type="module" src="assets/js/starter.js"></script>
</body>

</html>